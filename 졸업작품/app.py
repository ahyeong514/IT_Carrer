# -*- coding: utf-8 -*-

# === 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ===
import os
import re
from flask import Flask, request, jsonify, render_template
from flask_cors import CORS
import fitz  # PDF ì²˜ë¦¬ë¥¼ ìœ„í•œ PyMuPDF
import ollama
import chromadb
from sentence_transformers import SentenceTransformer
import urllib.request
import json
import requests
import time
from bs4 import BeautifulSoup
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC


# ë„¤ì´ë²„ API ì¸ì¦ ì •ë³´
CLIENT_ID = "Gsw3EKqttspCGXo8GXUr"
CLIENT_SECRET = "Nd76GbAAKv"

# === 2. Flask ì•± ì´ˆê¸°í™” ===
app = Flask(__name__)
CORS(app)  # Cross-Origin Resource Sharing (CORS) í™œì„±í™”

# === 3. ì„¤ì • ë³€ìˆ˜ ===
# --- ì´ ìŠ¤í¬ë¦½íŠ¸ê°€ ìœ„ì¹˜í•œ ë””ë ‰í† ë¦¬ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# --- ë¦¬ì†ŒìŠ¤ì˜ ì ˆëŒ€ ê²½ë¡œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤
PDF_FILE_PATH = os.path.join(BASE_DIR, "job.pdf")
CHROMA_DB_PATH = os.path.join(BASE_DIR, "chroma_db")

# --- ëª¨ë¸ ë° RAG ì„¤ì •
# Ollamaì—ì„œ ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤.
MODEL_NAME = "exaone3.5:2.4b"
# ChromaDB ì»¬ë ‰ì…˜ì˜ ì´ë¦„ì…ë‹ˆë‹¤.
CHROMA_COLLECTION_NAME = "pdf_chatbot_collection"
# ì„ë² ë”© ìƒì„±ì„ ìœ„í•œ Sentence Transformer ëª¨ë¸ì…ë‹ˆë‹¤.
EMBEDDING_MODEL_NAME = "intfloat/multilingual-e5-small"
# ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ê°€ì ¸ì˜¬ ê´€ë ¨ì„± ë†’ì€ ì²­í¬ì˜ ìˆ˜ì…ë‹ˆë‹¤.
TOP_K_CHUNKS = 3

# === 4. RAG ì‹œìŠ¤í…œì„ ìœ„í•œ ì „ì—­ ë³€ìˆ˜ ===
# ì„œë²„ê°€ ì‹œì‘ë  ë•Œ í•œ ë²ˆ ì´ˆê¸°í™”ë©ë‹ˆë‹¤.
embedder = None
chroma_collection = None

# === 5. RAG ì‹œìŠ¤í…œ í•µì‹¬ í•¨ìˆ˜ ===

def read_pdf_chunks(file_path, chunk_size=500, overlap=50):
    """
    PDF íŒŒì¼ì„ ì½ê³ , í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•œ í›„, ë‹¤ë£¨ê¸° ì‰¬ìš´ ì¡°ê°(chunk)ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.
    """
    if not os.path.exists(file_path):
        print(f"âŒ ì˜¤ë¥˜: '{file_path}' ê²½ë¡œì—ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    try:
        doc = fitz.open(file_path)
        full_text = "".join(page.get_text("text") for page in doc)
        doc.close()
        
        if not full_text.strip():
            print("âŒ ê²½ê³ : PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí–ˆì§€ë§Œ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            return []

        # ì—¬ëŸ¬ ê°œì˜ ê³µë°± ë¬¸ìë¥¼ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´í•˜ì—¬ í…ìŠ¤íŠ¸ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤
        full_text = re.sub(r'\s+', ' ', full_text).strip()
        
        # í…ìŠ¤íŠ¸ë¥¼ ê²¹ì¹˜ëŠ” ë¶€ë¶„ì´ ìˆë„ë¡ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤
        chunks = [
            full_text[i:i + chunk_size]
            for i in range(0, len(full_text), chunk_size - overlap)
        ]
        return chunks
    except Exception as e:
        print(f"âŒ PDF íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

def initialize_rag_system():
    """
    RAG ì‹œìŠ¤í…œì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤: ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    ë§Œì•½ ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìœ¼ë©´, PDFë¥¼ ì²˜ë¦¬í•˜ì—¬ DBë¥¼ ì±„ì›ë‹ˆë‹¤.
    """
    global embedder, chroma_collection
    print("ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤...")
    try:
        # Sentence Transformer ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤
        embedder = SentenceTransformer(EMBEDDING_MODEL_NAME)
        print("âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

        # ì˜êµ¬ ì €ì¥ë˜ëŠ” ChromaDB í´ë¼ì´ì–¸íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤
        client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
        chroma_collection = client.get_or_create_collection(name=CHROMA_COLLECTION_NAME)

        # ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìœ¼ë©´ PDFë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤
        if chroma_collection.count() == 0:
            print(f"âš ï¸ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. '{PDF_FILE_PATH}' íŒŒì¼ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤...")
            pdf_chunks = read_pdf_chunks(PDF_FILE_PATH)
            
            if not pdf_chunks:
                print(f"âŒ PDF íŒŒì¼ì„ ì½ê±°ë‚˜ ì²˜ë¦¬í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. RAG ì‹œìŠ¤í…œì´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                return

            # --- â˜…â˜…â˜… ì²­í¬ ë‚´ìš© í™•ì¸ì„ ìœ„í•œ ë””ë²„ê¹… ì½”ë“œ â˜…â˜…â˜… ---
            print("\n" + "="*20 + " PDFì—ì„œ ìƒì„±ëœ í…ìŠ¤íŠ¸ ì²­í¬ (ìµœëŒ€ 5ê°œ) " + "="*20)
            for i, chunk in enumerate(pdf_chunks[:5]): # í„°ë¯¸ë„ì— ë„ˆë¬´ ë§ì´ í‘œì‹œë˜ì§€ ì•Šë„ë¡ ìµœëŒ€ 5ê°œë§Œ ì¶œë ¥
                print(f"--- ì²­í¬ {i+1} ---")
                print(chunk)
                print("-" * (len(f"--- ì²­í¬ {i+1} ---")))
            if len(pdf_chunks) > 5:
                print(f"...... (ì´ {len(pdf_chunks)}ê°œì˜ ì²­í¬ ì¤‘ ì• 5ê°œë§Œ í‘œì‹œ)")
            print("="*67 + "\n")
            # --- â˜…â˜…â˜… ë””ë²„ê¹… ì½”ë“œ ë â˜…â˜…â˜… ---

            # ê° ì¡°ê°ì— ëŒ€í•œ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤
            chunk_embeddings = embedder.encode(pdf_chunks, show_progress_bar=True)
            ids = [str(i) for i in range(len(pdf_chunks))]
            
            # ë°ì´í„°ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€í•©ë‹ˆë‹¤
            chroma_collection.add(embeddings=chunk_embeddings, documents=pdf_chunks, ids=ids)
            print(f"âœ… ë°ì´í„°ë² ì´ìŠ¤ì— {len(pdf_chunks)}ê°œì˜ ë¬¸ì„œ ì¡°ê°ì„ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        else:
            print(f"âœ… ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ {chroma_collection.count()}ê°œì˜ ì„ë² ë”©ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            
        print("ğŸ‰ RAG ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

# app.py íŒŒì¼ì˜ ê¸°ì¡´ run_ollama_chat í•¨ìˆ˜ë¥¼ ì•„ë˜ ì½”ë“œë¡œ ì „ì²´ êµì²´í•˜ì„¸ìš”.

def run_ollama_chat(question, history):
    """
    ì£¼ìš” RAG ë¡œì§ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤: ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•˜ê³  ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    if chroma_collection is None:
        return "ì˜¤ë¥˜: RAG ì‹œìŠ¤í…œì´ ì œëŒ€ë¡œ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
    
    try:
        # 1. ChromaDBì—ì„œ ê´€ë ¨ì„± ë†’ì€ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤
        results = chroma_collection.query(query_texts=[question], n_results=TOP_K_CHUNKS)
        
        if not results['documents'] or not results['documents'][0]:
            return "ì£„ì†¡í•©ë‹ˆë‹¤, ì£¼ì–´ì§„ ë¬¸ì„œì—ì„œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤."

        context = "\n---\n".join(results['documents'][0])

        # 2. ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤
        system_prompt = (
            "ë‹¹ì‹ ì€ ì œê³µëœ ë¬¸ì„œì˜ ì»¨í…ìŠ¤íŠ¸(context)ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì§€ëŠ¥í˜• ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. "
            "ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ í•´ì•¼ í•©ë‹ˆë‹¤. 'CONTEXT' ì„¹ì…˜ì— ì£¼ì–´ì§„ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ê°„ê²°í•˜ê³  ì§ì ‘ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”. "
            "ë§Œì•½ ì»¨í…ìŠ¤íŠ¸ì— ë‹µë³€ì´ í¬í•¨ë˜ì–´ ìˆì§€ ì•Šë‹¤ë©´, ë°˜ë“œì‹œ 'ì£¼ì–´ì§„ ë¬¸ì„œ ë‚´ìš©ìœ¼ë¡œëŠ” ë‹µë³€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'ë¼ê³  ë§í•´ì•¼ í•©ë‹ˆë‹¤. "
            "ì™¸ë¶€ ì§€ì‹ì„ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."
        )
        
        prompt_with_context = f"""
[CONTEXT]
{context}

[QUESTION]
{question}
"""
        # 3. Ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤
        messages = [{"role": "system", "content": system_prompt}]
        messages.extend(history)
        messages.append({"role": "user", "content": prompt_with_context})
        
        # â–¼â–¼â–¼â–¼â–¼ [í•µì‹¬ ìˆ˜ì •] ì´ ë¶€ë¶„ì´ ë°”ë€Œì—ˆìŠµë‹ˆë‹¤! â–¼â–¼â–¼â–¼â–¼
        
        # Ollama í´ë¼ì´ì–¸íŠ¸ë¥¼ ì§ì ‘ ë§Œë“¤ì–´ì„œ timeoutì„ 60ì´ˆë¡œ ë„‰ë„‰í•˜ê²Œ ì„¤ì •í•©ë‹ˆë‹¤.
        # ì´ë ‡ê²Œ í•˜ë©´ ëª¨ë¸ì´ ë¡œë”©ë˜ëŠ” ì‹œê°„ì„ ì¶©ë¶„íˆ ê¸°ë‹¤ë ¤ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        client = ollama.Client(host='http://localhost:11434', timeout=60)
        response = client.chat(model=MODEL_NAME, messages=messages)
        
        # â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²â–²

        answer = response["message"]["content"].strip()
        
        return answer

    except Exception as e:
        print(f"ğŸ’¥ RAG ì±„íŒ… ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # í”í•œ ë¬¸ì œì— ëŒ€í•´ ë„ì›€ì´ ë˜ëŠ” ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ì œê³µí•©ë‹ˆë‹¤
        if "model not found" in str(e):
            return f"Ollama ì˜¤ë¥˜: '{MODEL_NAME}' ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'ollama pull {MODEL_NAME}' ëª…ë ¹ì–´ë¡œ ëª¨ë¸ì„ ì„¤ì¹˜í•´ì£¼ì„¸ìš”."
        # [ì¶”ê°€] Timeout ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ë” ì¹œì ˆí•˜ê²Œ ë³´ì—¬ì¤ë‹ˆë‹¤.
        elif "timed out" in str(e):
            return "Ollama ì‘ë‹µ ì‹œê°„ ì´ˆê³¼: ëª¨ë¸ì„ ë¡œë”©í•˜ëŠ” ë° ì‹œê°„ì´ ë” í•„ìš”í•©ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        elif "connection refused" in str(e):
            return "Ollama ì˜¤ë¥˜: Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì´ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
        return "ì£„ì†¡í•©ë‹ˆë‹¤, ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì„œë²„ì— ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

def get_it_jobs():
    """ë„¤ì´ë²„ 'ë¸”ë¡œê·¸' ê²€ìƒ‰ APIë¥¼ ì´ìš©í•´ 'IT ì±„ìš©' ê´€ë ¨ í¬ìŠ¤íŒ…ì„ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    try:
        encText = urllib.parse.quote("IT ì±„ìš© ê³µê³ ")
        url = "https://openapi.naver.com/v1/search/blog?query=" + encText + "&display=5&sort=sim"
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", CLIENT_ID)
        request.add_header("X-Naver-Client-Secret", CLIENT_SECRET)
        
        response = urllib.request.urlopen(request)
        rescode = response.getcode()

        if rescode == 200:
            response_body = response.read().decode('utf-8')
            blog_data = json.loads(response_body)
            
            postings = []
            for item in blog_data['items']:
                title = item['title'].replace('<b>', '').replace('</b>', '')
                link = item['link']
                # ë¸”ë¡œê·¸ ê²€ìƒ‰ ê²°ê³¼ì—ëŠ” 'íšŒì‚¬ëª…'ì´ ì—†ìœ¼ë¯€ë¡œ, ì œëª©ê³¼ ë§í¬ë§Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
                postings.append({'title': title, 'link': link})
            
            return postings
        else:
            return []
    except Exception as e:
        print(f"ë¸”ë¡œê·¸ í¬ìŠ¤íŒ… ê²€ìƒ‰ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        return []

def get_it_news():
    """ë„¤ì´ë²„ ë‰´ìŠ¤ APIë¥¼ í˜¸ì¶œí•˜ì—¬ IT ë‰´ìŠ¤ 20ê°œë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜"""
    try:
        encText = urllib.parse.quote("IT ì§ì¢…")
        url = "https://openapi.naver.com/v1/search/news?query=" + encText + "&display=20&sort=sim"
        
        request = urllib.request.Request(url)
        request.add_header("X-Naver-Client-Id", CLIENT_ID)
        request.add_header("X-Naver-Client-Secret", CLIENT_SECRET)
        
        response = urllib.request.urlopen(request)
        rescode = response.getcode()

        if rescode == 200:
            response_body = response.read().decode('utf-8')
            news_data = json.loads(response_body)
            
            # ê¸°ì‚¬ ëª©ë¡ì„ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
            articles = []
            for item in news_data['items']:
                # HTML íƒœê·¸ ì œê±°
                title = item['title'].replace('<b>', '').replace('</b>', '')
                link = item['link']
                
                # ê° ê¸°ì‚¬ë¥¼ ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ì €ì¥í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                articles.append({'title': title, 'link': link})
            
            return articles # print ëŒ€ì‹ , ê°€ê³µëœ ë‰´ìŠ¤ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜!
        else:
            return [] # ì—ëŸ¬ ë°œìƒ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    except Exception as e:
        print(f"Error fetching news: {e}")
        return [] # ì˜ˆì™¸ ë°œìƒ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    
# === 6. Flask API ì—”ë“œí¬ì¸íŠ¸ (ë¼ìš°íŠ¸) ===

@app.route('/')
def home():
    news_articles = get_it_news()   # ê¸°ì¡´ ë‰´ìŠ¤ í¬ë¡¤ë§ í•¨ìˆ˜
    job_postings = get_it_jobs()    # ìƒˆë¡œ ì¶”ê°€í•œ ì±„ìš© ê³µê³  í¬ë¡¤ë§ í•¨ìˆ˜

    return render_template(
        'home.html', 
        news_list=news_articles, 
        job_list=job_postings  # job_list ë¼ëŠ” ì´ë¦„ìœ¼ë¡œ ì±„ìš© ê³µê³  ë°ì´í„°ë¥¼ ì „ë‹¬
    )

@app.route('/chatbot')
def chatbot():
    return render_template('chatbot.html')

@app.route('/taja')
def taja():
    return render_template('taja.html')

@app.route('/mypage')
def mypage():
    return render_template('mypage.html')

@app.route('/IT')
def IT():
    return render_template('IT.html')

@app.route('/login')
def login():
    return render_template('login.html')

@app.route('/ask', methods=['POST'])
def ask_chatbot():
    """ ì±—ë´‡ì„ ìœ„í•œ ë©”ì¸ API ì—”ë“œí¬ì¸íŠ¸ì…ë‹ˆë‹¤. """
    if embedder is None or chroma_collection is None:
        return jsonify({"error": "RAG ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 500
        
    data = request.json
    question = data.get('question', '')
    history = data.get('history', [])
    
    if not question:
        return jsonify({"error": "ì§ˆë¬¸ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400
        
    answer = run_ollama_chat(question, history)
    
    # ë‹¤ìŒ ì°¨ë¡€ë¥¼ ìœ„í•´ ëŒ€í™” ê¸°ë¡ì„ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.
    updated_history = history + [{"role": "user", "content": question}, {"role": "assistant", "content": answer}]
    
    return jsonify({"answer": answer, "history": updated_history})


# === 7. ë©”ì¸ ì‹¤í–‰ ë¸”ë¡ ===
if __name__ == "__main__":
    initialize_rag_system()
    print(f"ğŸ’¬ Flask ì„œë²„ê°€ http://localhost:5000 ì—ì„œ ì‹œì‘ë©ë‹ˆë‹¤. ëª¨ë¸: {MODEL_NAME}")
    app.run(host='0.0.0.0', port=5000, debug=True)

